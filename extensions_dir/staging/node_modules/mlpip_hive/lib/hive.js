import { executePython, logServerException, showErrorToast } from './NotebookUtils';
import HiveSessionConnector from './Components/HiveSessionConnector';
import * as React from 'react';
import { Dialog, ReactWidget, ToolbarButton } from '@jupyterlab/apputils';
import { NbMetadata } from './metadata';
import { INotification } from 'jupyterlab_toastify';
/**
 * The CSS class for a Toolbar icon.
 */
const CSS_ICON_CLASS = 'jp-OfflineNotebookToolbarIcon';
export function getSparkButton(panel, nbContext, className) {
    setupNewCellListener(panel, nbContext);
    return getSparkConnectionButton(panel, nbContext, className);
}
function setupNewCellListener(panel, context) {
    context.model.cells.changed.connect((list, args) => {
        if (new NbMetadata(context).getSparkSessionSettings()["prepend_new_cells_with_spark_magic"]) {
            if (args.type == "add") {
                args.newValues.forEach(cellModel => {
                    if (cellModel.type == "code") {
                        panel.content.widgets[args.newIndex].inputArea.model.value.text = "%%spark";
                    }
                });
            }
        }
    });
}
function getSparkConnectionButton(panel, nbContext, className) {
    return new ToolbarButton({
        className: className,
        label: 'Connect to Spark Session',
        iconClass: 'fas fa-database ' + CSS_ICON_CLASS,
        onClick: () => {
            showHiveConnectionUiModal(panel.sessionContext, nbContext)
                .then(connectToSpark.bind(null, panel.sessionContext, nbContext))
                .catch((reason) => {
                console.error(reason);
            });
        }
    });
}
function getConfOverrideCode(state, nbContext) {
    const selectedHiveDbs = state.hiveDbSelected.map((selection) => selection.value);
    const installedPackages = new NbMetadata(nbContext).getInstalledPackages();
    return `from dropbox.ml_platform.jupyterhub.kernels.resources.hive_connector_utils import override_sparkmagic_conf
override_sparkmagic_conf({
    "cluster": "${state.heraclesCluster}",
    "heracles_app": "${state.heraclesApp}",
    "driver_memory": "${state.driverMemory}",
    "driver_cores": ${state.driverCores},
    "executor_memory": "${state.executorMemory}",
    "executor_cores": ${state.executorCores},
    "num_executors": ${state.numExecutors},
    "hive_databases": ${JSON.stringify(selectedHiveDbs)},
    "enable_arrow_execution": ${state.enableArrowExecution ? "True" : "False"},
    "verify_partitions": ${state.verifyPartitions ? "True" : "False"},
    "read_access_clogger": ${state.readAccessClogger ? "True" : "False"},
    "read_access_events": ${state.readAccessEvents ? "True" : "False"},
    "read_access_events_staging": ${state.readAccessEventsStaging ? "True" : "False"},
    "read_access_dummy": ${state.readAccessDummy ? "True" : "False"},
    "packages": ${JSON.stringify(installedPackages)},
    })`;
}
function connectToSpark(sessionContext, nbContext, state) {
    return INotification.inProgress("Connecting to Spark...!", {}).then((notifier_id) => {
        executePython(sessionContext.session.kernel, getConfOverrideCode(state, nbContext))
            .then(control => {
            INotification.update({
                toastId: notifier_id,
                message: "Connecting to Spark...",
            });
            return executePython(sessionContext.session.kernel, `from dropbox.ml_platform.jupyterhub.kernels.resources.hive_connector_utils import connect_to_hive
connect_to_hive()`);
        })
            .then(control => {
            INotification.update({
                toastId: notifier_id,
                message: "Connected to Spark",
                autoClose: 5000,
                type: "success"
            });
            console.log(control);
        })
            .catch(err_msg => {
            showErrorToast(notifier_id, "Connection to Spark Failed ");
            logServerException(err_msg.content);
        });
    });
}
function makeHiveConnectionForm(ref, sessionContext, nbContext) {
    const form = (React.createElement("div", { className: "hive-connect-form" },
        React.createElement("form", null,
            React.createElement("p", null,
                "By choosing Hive databases from the below list, you will be able to run live Hive queries to read from these databases in the current notebook. However, you have read/write access to databases under your own namespace, i.e. ",
                React.createElement("code", null, "username"),
                " and ",
                React.createElement("code", null, "restricted_username"),
                "."),
            React.createElement("br", null),
            React.createElement("p", null,
                "Simply preface a notebook cell with ",
                React.createElement("code", null, "%%spark"),
                " to run pyspark code, or ",
                React.createElement("code", null, "%%spark -c sql"),
                " to run a SQL query directly. You can find a more comprehensive walkthrough guide ",
                React.createElement("a", { href: "https://jupyterhub.pp.dropbox.com/user/_/notebooks/users/aleksander/Hive%20Connector%20Guide.ipynb" }, "here"),
                "."),
            React.createElement("br", null),
            React.createElement("p", null,
                "This tool is mainly meant for data exploration and small-scale prototyping. For larger-scale non-interactive queries, use ",
                React.createElement("a", { href: "https://www.dropbox.com/scl/fi/pm82gzzrqopbnf213lfqu/JupyterHub-environment.paper?dl=0&rlkey=hzrg0rb0yf93hlbewjwv8by7c#:uid=082866284532065405821117&h2=Hive-data-access-:yellow_dot:", target: "_blank", rel: "noreferrer" },
                    React.createElement("code", null, "import_hive_data_to_hdfs")),
                "."),
            React.createElement("br", null),
            React.createElement("p", null,
                React.createElement("em", null,
                    "Note: This feature launched recently! Please feel free to give feedback to ",
                    React.createElement("code", null, "#ml-platform"),
                    " on Slack :)")),
            React.createElement(HiveSessionConnector, { ref: ref, sessionContext: sessionContext, nbContext: nbContext }))));
    return form;
}
class HiveConnectorWidget extends ReactWidget {
    constructor(ref, sessionContext, nbContext) {
        super();
        this._connector_ref = ref;
        this._sessionContext = sessionContext;
        this._nbContext = nbContext;
    }
    render() {
        return makeHiveConnectionForm(this._connector_ref, this._sessionContext, this._nbContext);
    }
    getValue() {
        return this._connector_ref.current.state; // This is returned by the Dialog in the result
    }
}
function showHiveConnectionUiModal(sessionContext, nbContext) {
    return new Promise((resolve, reject) => {
        const ref = React.createRef();
        const connect_btn_label = "Connect";
        const cancel_btn_label = "Cancel";
        var spark_connector_dialog = new Dialog({
            title: 'Connect to Hive Databases',
            body: new HiveConnectorWidget(ref, sessionContext, nbContext),
            buttons: [
                Dialog.cancelButton({
                    label: cancel_btn_label
                }),
                Dialog.okButton({
                    accept: true,
                    label: connect_btn_label
                }),
            ],
        });
        spark_connector_dialog.launch().then((result) => {
            console.log(result);
            if (result.button.label == connect_btn_label) {
                HiveSessionConnector.saveStateAsNotebookMetadata(result.value, new NbMetadata(nbContext));
                resolve(result.value);
                return true;
            }
            else if (result.button.label == cancel_btn_label) {
                reject('dialog dismissed');
            }
            else {
                reject('no reference to Hive connector');
                return false;
            }
        });
    });
}
